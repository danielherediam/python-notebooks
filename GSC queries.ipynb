{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a584eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import httplib2\n",
    "import requests\n",
    " \n",
    "from collections import defaultdict\n",
    "from dateutil import relativedelta\n",
    "from googleapiclient.discovery import build\n",
    "from oauth2client import client\n",
    "from oauth2client import file\n",
    "from oauth2client import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c948c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def authorize_creds(creds,authorizedcreds='authorizedcreds.dat'):\n",
    "    '''\n",
    "    Authorize credentials using OAuth2.\n",
    "    '''\n",
    "    print('Authorizing Creds')\n",
    "    # Variable parameter that controls the set of resources that the access token permits.\n",
    "    SCOPES = ['https://www.googleapis.com/auth/webmasters.readonly'] \n",
    " \n",
    "    # Path to client_secrets.json file\n",
    "    CLIENT_SECRETS_PATH = creds\n",
    " \n",
    "    # Create a parser to be able to open browser for Authorization\n",
    "    parser = argparse.ArgumentParser(\n",
    "        formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "        parents=[tools.argparser])\n",
    "    flags = parser.parse_args([])\n",
    " \n",
    "    # Creates an authorization flow from a clientsecrets file.\n",
    "    # Will raise InvalidClientSecretsError for unknown types of Flows.\n",
    "    flow = client.flow_from_clientsecrets(\n",
    "        CLIENT_SECRETS_PATH, scope = SCOPES,\n",
    "        message = tools.message_if_missing(CLIENT_SECRETS_PATH))\n",
    " \n",
    "    # Prepare credentials and authorize HTTP\n",
    "    # If they exist, get them from the storage object\n",
    "    # credentials will get written back to the 'authorizedcreds.dat' file.\n",
    "    storage = file.Storage(authorizedcreds)\n",
    "    credentials = storage.get()\n",
    " \n",
    "    # If authenticated credentials don't exist, open Browser to authenticate\n",
    "    if credentials is None or credentials.invalid:\n",
    "        credentials = tools.run_flow(flow, storage, flags)      # Add the valid creds to a variable\n",
    " \n",
    "    # Take the credentials and authorize them using httplib2   \n",
    "    http = httplib2.Http()                                      # Creates an HTTP client object to make the http request\n",
    "    http = credentials.authorize(http=http)                     # Sign each request from the HTTP client with the OAuth 2.0 access token\n",
    "    webmasters_service = build('searchconsole', 'v1', http=http)   # Construct a Resource to interact with the API using the Authorized HTTP Client.\n",
    " \n",
    "    print('Auth Successful')\n",
    "    return webmasters_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "868b8bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authorizing Creds\n",
      "\n",
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=307858290080-jdbltqmkqqg6v3vj3ud47oj8u58tl2b9.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fwebmasters.readonly&access_type=offline&response_type=code\n",
      "\n",
      "If your browser is on a different machine then exit and re-run this\n",
      "application with the command-line parameter\n",
      "\n",
      "  --noauth_local_webserver\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielheredia/opt/anaconda3/lib/python3.9/site-packages/oauth2client/_helpers.py:255: UserWarning: Cannot access authorizedcreds.dat: No such file or directory\n",
      "  warnings.warn(_MISSING_FILE_MESSAGE.format(filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication successful.\n",
      "Auth Successful\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    creds = 'api-json-gsc.json'\n",
    "    webmasters_service = authorize_creds(creds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffa6281f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sc-domain:wordcounter.ai\n",
      "sc-domain:lettersolver.com\n",
      "sc-domain:wordfinderx.com\n",
      "sc-domain:word.tips\n",
      "sc-domain:crossword-solver.io\n"
     ]
    }
   ],
   "source": [
    "site_list = webmasters_service.sites().list().execute()\n",
    " \n",
    "verified_sites_urls = [s['siteUrl'] for s in site_list['siteEntry']\n",
    "                       if s['permissionLevel'] != 'siteUnverifiedUser'\n",
    "                          and s['siteUrl'][:4] == 'sc-d']\n",
    " \n",
    "for site_url in verified_sites_urls:\n",
    "  print( site_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "747ffbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def execute_request(service, property_uri, request):\n",
    "    return service.searchanalytics().query(siteUrl=property_uri, body=request).execute()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad15e4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data for today minus 365\n",
      "Extracting data for today minus 364\n",
      "Extracting data for today minus 363\n",
      "Extracting data for today minus 362\n",
      "Extracting data for today minus 361\n",
      "Extracting data for today minus 360\n",
      "Extracting data for today minus 359\n",
      "Extracting data for today minus 358\n",
      "Extracting data for today minus 357\n",
      "Extracting data for today minus 356\n",
      "Extracting data for today minus 355\n",
      "Extracting data for today minus 354\n",
      "Extracting data for today minus 353\n",
      "Extracting data for today minus 352\n",
      "Extracting data for today minus 351\n",
      "Extracting data for today minus 350\n",
      "Extracting data for today minus 349\n",
      "Extracting data for today minus 348\n",
      "Extracting data for today minus 347\n",
      "Extracting data for today minus 346\n",
      "Extracting data for today minus 345\n",
      "Extracting data for today minus 344\n",
      "Extracting data for today minus 343\n",
      "Extracting data for today minus 342\n",
      "Extracting data for today minus 341\n",
      "Extracting data for today minus 340\n",
      "Extracting data for today minus 339\n",
      "Extracting data for today minus 338\n",
      "Extracting data for today minus 337\n",
      "Extracting data for today minus 336\n",
      "Extracting data for today minus 335\n",
      "Extracting data for today minus 334\n",
      "Extracting data for today minus 333\n",
      "Extracting data for today minus 332\n",
      "Extracting data for today minus 331\n",
      "Extracting data for today minus 330\n",
      "Extracting data for today minus 329\n",
      "Extracting data for today minus 328\n",
      "Extracting data for today minus 327\n",
      "Extracting data for today minus 326\n",
      "Extracting data for today minus 325\n",
      "Extracting data for today minus 324\n",
      "Extracting data for today minus 323\n",
      "Extracting data for today minus 322\n",
      "Extracting data for today minus 321\n",
      "Extracting data for today minus 320\n",
      "Extracting data for today minus 319\n",
      "Extracting data for today minus 318\n",
      "Extracting data for today minus 317\n",
      "Extracting data for today minus 316\n",
      "Extracting data for today minus 315\n",
      "Extracting data for today minus 314\n",
      "Extracting data for today minus 313\n",
      "Extracting data for today minus 312\n",
      "Extracting data for today minus 311\n",
      "Extracting data for today minus 310\n",
      "Extracting data for today minus 309\n",
      "Extracting data for today minus 308\n",
      "Extracting data for today minus 307\n",
      "Extracting data for today minus 306\n",
      "Extracting data for today minus 305\n",
      "Extracting data for today minus 304\n",
      "Extracting data for today minus 303\n",
      "Extracting data for today minus 302\n",
      "Extracting data for today minus 301\n",
      "Extracting data for today minus 300\n",
      "Extracting data for today minus 299\n",
      "Extracting data for today minus 298\n",
      "Extracting data for today minus 297\n",
      "Extracting data for today minus 296\n",
      "Extracting data for today minus 295\n",
      "Extracting data for today minus 294\n",
      "Extracting data for today minus 293\n",
      "Extracting data for today minus 292\n",
      "Extracting data for today minus 291\n",
      "Extracting data for today minus 290\n",
      "Extracting data for today minus 289\n",
      "Extracting data for today minus 288\n",
      "Extracting data for today minus 287\n",
      "Extracting data for today minus 286\n",
      "Extracting data for today minus 285\n",
      "Extracting data for today minus 284\n",
      "Extracting data for today minus 283\n",
      "Extracting data for today minus 282\n",
      "Extracting data for today minus 281\n",
      "Extracting data for today minus 280\n",
      "Extracting data for today minus 279\n",
      "Extracting data for today minus 278\n",
      "Extracting data for today minus 277\n",
      "Extracting data for today minus 276\n",
      "Extracting data for today minus 275\n",
      "Extracting data for today minus 274\n",
      "Extracting data for today minus 273\n",
      "Extracting data for today minus 272\n",
      "Extracting data for today minus 271\n",
      "Extracting data for today minus 270\n",
      "Extracting data for today minus 269\n",
      "Extracting data for today minus 268\n",
      "Extracting data for today minus 267\n",
      "Extracting data for today minus 266\n",
      "Extracting data for today minus 265\n",
      "Extracting data for today minus 264\n",
      "Extracting data for today minus 263\n",
      "Extracting data for today minus 262\n",
      "Extracting data for today minus 261\n",
      "Extracting data for today minus 260\n",
      "Extracting data for today minus 259\n",
      "Extracting data for today minus 258\n",
      "Extracting data for today minus 257\n",
      "Extracting data for today minus 256\n",
      "Extracting data for today minus 255\n",
      "Extracting data for today minus 254\n",
      "Extracting data for today minus 253\n",
      "Extracting data for today minus 252\n",
      "Extracting data for today minus 251\n",
      "Extracting data for today minus 250\n",
      "Extracting data for today minus 249\n",
      "Extracting data for today minus 248\n",
      "Extracting data for today minus 247\n",
      "Extracting data for today minus 246\n",
      "Extracting data for today minus 245\n",
      "Extracting data for today minus 244\n",
      "Extracting data for today minus 243\n",
      "Extracting data for today minus 242\n",
      "Extracting data for today minus 241\n",
      "Extracting data for today minus 240\n",
      "Extracting data for today minus 239\n",
      "Extracting data for today minus 238\n",
      "Extracting data for today minus 237\n",
      "Extracting data for today minus 236\n",
      "Extracting data for today minus 235\n",
      "Extracting data for today minus 234\n",
      "Extracting data for today minus 233\n",
      "Extracting data for today minus 232\n",
      "Extracting data for today minus 231\n",
      "Extracting data for today minus 230\n",
      "Extracting data for today minus 229\n",
      "Extracting data for today minus 228\n",
      "Extracting data for today minus 227\n",
      "Extracting data for today minus 226\n",
      "Extracting data for today minus 225\n",
      "Extracting data for today minus 224\n",
      "Extracting data for today minus 223\n",
      "Extracting data for today minus 222\n",
      "Extracting data for today minus 221\n",
      "Extracting data for today minus 220\n",
      "Extracting data for today minus 219\n",
      "Extracting data for today minus 218\n",
      "Extracting data for today minus 217\n",
      "Extracting data for today minus 216\n",
      "Extracting data for today minus 215\n",
      "Extracting data for today minus 214\n",
      "Extracting data for today minus 213\n",
      "Extracting data for today minus 212\n",
      "Extracting data for today minus 211\n",
      "Extracting data for today minus 210\n",
      "Extracting data for today minus 209\n",
      "Extracting data for today minus 208\n",
      "Extracting data for today minus 207\n",
      "Extracting data for today minus 206\n",
      "Extracting data for today minus 205\n",
      "Extracting data for today minus 204\n",
      "Extracting data for today minus 203\n",
      "Extracting data for today minus 202\n",
      "Extracting data for today minus 201\n",
      "Extracting data for today minus 200\n",
      "Extracting data for today minus 199\n",
      "Extracting data for today minus 198\n",
      "Extracting data for today minus 197\n",
      "Extracting data for today minus 196\n",
      "Extracting data for today minus 195\n",
      "Extracting data for today minus 194\n",
      "Extracting data for today minus 193\n",
      "Extracting data for today minus 192\n",
      "Extracting data for today minus 191\n",
      "Extracting data for today minus 190\n",
      "Extracting data for today minus 189\n",
      "Extracting data for today minus 188\n",
      "Extracting data for today minus 187\n",
      "Extracting data for today minus 186\n",
      "Extracting data for today minus 185\n",
      "Extracting data for today minus 184\n",
      "Extracting data for today minus 183\n",
      "Extracting data for today minus 182\n",
      "Extracting data for today minus 181\n",
      "Extracting data for today minus 180\n",
      "Extracting data for today minus 179\n",
      "Extracting data for today minus 178\n",
      "Extracting data for today minus 177\n",
      "Extracting data for today minus 176\n",
      "Extracting data for today minus 175\n",
      "Extracting data for today minus 174\n",
      "Extracting data for today minus 173\n",
      "Extracting data for today minus 172\n",
      "Extracting data for today minus 171\n",
      "Extracting data for today minus 170\n",
      "Extracting data for today minus 169\n",
      "Extracting data for today minus 168\n",
      "Extracting data for today minus 167\n",
      "Extracting data for today minus 166\n",
      "Extracting data for today minus 165\n",
      "Extracting data for today minus 164\n",
      "Extracting data for today minus 163\n",
      "Extracting data for today minus 162\n",
      "Extracting data for today minus 161\n",
      "Extracting data for today minus 160\n",
      "Extracting data for today minus 159\n",
      "Extracting data for today minus 158\n",
      "Extracting data for today minus 157\n",
      "Extracting data for today minus 156\n",
      "Extracting data for today minus 155\n",
      "Extracting data for today minus 154\n",
      "Extracting data for today minus 153\n",
      "Extracting data for today minus 152\n",
      "Extracting data for today minus 151\n",
      "Extracting data for today minus 150\n",
      "Extracting data for today minus 149\n",
      "Extracting data for today minus 148\n",
      "Extracting data for today minus 147\n",
      "Extracting data for today minus 146\n",
      "Extracting data for today minus 145\n",
      "Extracting data for today minus 144\n",
      "Extracting data for today minus 143\n",
      "Extracting data for today minus 142\n",
      "Extracting data for today minus 141\n",
      "Extracting data for today minus 140\n",
      "Extracting data for today minus 139\n",
      "Extracting data for today minus 138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data for today minus 137\n",
      "Extracting data for today minus 136\n",
      "Extracting data for today minus 135\n",
      "Extracting data for today minus 134\n",
      "Extracting data for today minus 133\n",
      "Extracting data for today minus 132\n",
      "Extracting data for today minus 131\n",
      "Extracting data for today minus 130\n",
      "Extracting data for today minus 129\n",
      "Extracting data for today minus 128\n",
      "Extracting data for today minus 127\n",
      "Extracting data for today minus 126\n",
      "Extracting data for today minus 125\n",
      "Extracting data for today minus 124\n",
      "Extracting data for today minus 123\n",
      "Extracting data for today minus 122\n",
      "Extracting data for today minus 121\n",
      "Extracting data for today minus 120\n",
      "Extracting data for today minus 119\n",
      "Extracting data for today minus 118\n",
      "Extracting data for today minus 117\n",
      "Extracting data for today minus 116\n",
      "Extracting data for today minus 115\n",
      "Extracting data for today minus 114\n",
      "Extracting data for today minus 113\n",
      "Extracting data for today minus 112\n",
      "Extracting data for today minus 111\n",
      "Extracting data for today minus 110\n",
      "Extracting data for today minus 109\n",
      "Extracting data for today minus 108\n",
      "Extracting data for today minus 107\n",
      "Extracting data for today minus 106\n",
      "Extracting data for today minus 105\n",
      "Extracting data for today minus 104\n",
      "Extracting data for today minus 103\n",
      "Extracting data for today minus 102\n",
      "Extracting data for today minus 101\n",
      "Extracting data for today minus 100\n",
      "Extracting data for today minus 99\n",
      "Extracting data for today minus 98\n",
      "Extracting data for today minus 97\n",
      "Extracting data for today minus 96\n",
      "Extracting data for today minus 95\n",
      "Extracting data for today minus 94\n",
      "Extracting data for today minus 93\n",
      "Extracting data for today minus 92\n",
      "Extracting data for today minus 91\n",
      "Extracting data for today minus 90\n",
      "Extracting data for today minus 89\n",
      "Extracting data for today minus 88\n",
      "Extracting data for today minus 87\n",
      "Extracting data for today minus 86\n",
      "Extracting data for today minus 85\n",
      "Extracting data for today minus 84\n",
      "Extracting data for today minus 83\n",
      "Extracting data for today minus 82\n",
      "Extracting data for today minus 81\n",
      "Extracting data for today minus 80\n",
      "Extracting data for today minus 79\n",
      "Extracting data for today minus 78\n",
      "Extracting data for today minus 77\n",
      "Extracting data for today minus 76\n",
      "Extracting data for today minus 75\n",
      "Extracting data for today minus 74\n",
      "Extracting data for today minus 73\n",
      "Extracting data for today minus 72\n",
      "Extracting data for today minus 71\n",
      "Extracting data for today minus 70\n",
      "Extracting data for today minus 69\n",
      "Extracting data for today minus 68\n",
      "Extracting data for today minus 67\n",
      "Extracting data for today minus 66\n",
      "Extracting data for today minus 65\n",
      "Extracting data for today minus 64\n",
      "Extracting data for today minus 63\n",
      "Extracting data for today minus 62\n",
      "Extracting data for today minus 61\n",
      "Extracting data for today minus 60\n",
      "Extracting data for today minus 59\n",
      "Extracting data for today minus 58\n",
      "Extracting data for today minus 57\n",
      "Extracting data for today minus 56\n",
      "Extracting data for today minus 55\n",
      "Extracting data for today minus 54\n",
      "Extracting data for today minus 53\n",
      "Extracting data for today minus 52\n",
      "Extracting data for today minus 51\n",
      "Extracting data for today minus 50\n",
      "Extracting data for today minus 49\n",
      "Extracting data for today minus 48\n",
      "Extracting data for today minus 47\n",
      "Extracting data for today minus 46\n",
      "Extracting data for today minus 45\n",
      "Extracting data for today minus 44\n",
      "Extracting data for today minus 43\n",
      "Extracting data for today minus 42\n",
      "Extracting data for today minus 41\n",
      "Extracting data for today minus 40\n",
      "Extracting data for today minus 39\n",
      "Extracting data for today minus 38\n",
      "Extracting data for today minus 37\n",
      "Extracting data for today minus 36\n",
      "Extracting data for today minus 35\n",
      "Extracting data for today minus 34\n",
      "Extracting data for today minus 33\n",
      "Extracting data for today minus 32\n",
      "Extracting data for today minus 31\n",
      "Extracting data for today minus 30\n",
      "Extracting data for today minus 29\n",
      "Extracting data for today minus 28\n",
      "Extracting data for today minus 27\n",
      "Extracting data for today minus 26\n",
      "Extracting data for today minus 25\n",
      "Extracting data for today minus 24\n",
      "Extracting data for today minus 23\n",
      "Extracting data for today minus 22\n",
      "Extracting data for today minus 21\n",
      "Extracting data for today minus 20\n",
      "Extracting data for today minus 19\n",
      "Extracting data for today minus 18\n",
      "Extracting data for today minus 17\n",
      "Extracting data for today minus 16\n",
      "Extracting data for today minus 15\n",
      "Extracting data for today minus 14\n",
      "Extracting data for today minus 13\n",
      "Extracting data for today minus 12\n",
      "Extracting data for today minus 11\n",
      "Extracting data for today minus 10\n",
      "Extracting data for today minus 9\n",
      "Extracting data for today minus 8\n",
      "Extracting data for today minus 7\n",
      "Extracting data for today minus 6\n",
      "Extracting data for today minus 5\n",
      "Extracting data for today minus 4\n",
      "Extracting data for today minus 3\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "list_all = []\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "for dates in reversed(range(3,366)):\n",
    "    \n",
    "    print(\"Extracting data for today minus \" + str(dates))\n",
    "    \n",
    "    d = (datetime.today() - timedelta(days=dates)).strftime('%Y-%m-%d')\n",
    "\n",
    "    request = {\"startDate\": d, \"endDate\": d, \"dimensions\": [\"page\"], \"type\": \"web\"}\n",
    "\n",
    "    response = execute_request(webmasters_service, \"sc-domain:crossword-solver.io\" , request)\n",
    "\n",
    "\n",
    "    for iteration in response['rows']:\n",
    "        url = iteration[\"keys\"][0]\n",
    "        clicks = iteration[\"clicks\"]\n",
    "        impressions = iteration[\"impressions\"]\n",
    "        list_all.append([url,clicks,impressions,d])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ecd07c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(list_all, columns=[\"URL\", \"Clicks\", \"Impressions\", \"Date\"])\n",
    "df.to_csv('list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "38ec74cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_x = {}\n",
    "for x in list_all:\n",
    "    values = [x[1],x[2],x[3]]\n",
    "    key = x[0]\n",
    "    \n",
    "    try:\n",
    "        dict_x[key].append(values)\n",
    "    except KeyError:\n",
    "        dict_x[key] = [values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "69857e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_overperforming = []\n",
    "\n",
    "for keys,values in dict_x.items():\n",
    "    counter = 0\n",
    "    for y in range (len(values)):\n",
    "        if values[y][0] > 500:\n",
    "            counter = counter + 1\n",
    "    list_overperforming.append([keys,counter])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "eaba4827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[590, 2465, '2021-04-20'],\n",
       " [54, 294, '2021-04-21'],\n",
       " [16, 97, '2021-04-22'],\n",
       " [35, 402, '2021-04-28'],\n",
       " [157, 2882, '2021-04-29'],\n",
       " [15, 174, '2021-04-30'],\n",
       " [16, 82, '2021-05-01'],\n",
       " [35, 260, '2021-05-06'],\n",
       " [496, 6194, '2021-05-07'],\n",
       " [19, 68, '2021-05-12'],\n",
       " [63, 2194, '2021-05-14'],\n",
       " [22, 427, '2021-05-15'],\n",
       " [15, 66, '2021-05-18'],\n",
       " [37, 142, '2021-05-21'],\n",
       " [19, 107, '2021-05-29'],\n",
       " [52, 225, '2021-05-31'],\n",
       " [33, 131, '2021-06-17'],\n",
       " [29, 131, '2021-06-18'],\n",
       " [38, 114, '2021-06-19'],\n",
       " [53, 255, '2021-06-20'],\n",
       " [39, 169, '2021-06-21'],\n",
       " [24, 80, '2021-06-22'],\n",
       " [28, 88, '2021-06-23'],\n",
       " [22, 113, '2021-06-29'],\n",
       " [21, 132, '2021-07-01'],\n",
       " [16, 57, '2021-07-07'],\n",
       " [919, 4133, '2021-07-08'],\n",
       " [25, 427, '2021-07-09'],\n",
       " [27, 524, '2021-07-22'],\n",
       " [57, 239, '2021-07-26'],\n",
       " [63, 11206, '2021-08-20'],\n",
       " [30, 748, '2021-10-02'],\n",
       " [31, 136, '2021-10-19'],\n",
       " [100, 1832, '2021-10-22'],\n",
       " [65, 1000, '2021-10-23'],\n",
       " [82, 565, '2021-11-06'],\n",
       " [38, 226, '2021-11-10'],\n",
       " [43, 203, '2021-12-04'],\n",
       " [91, 753, '2021-12-31'],\n",
       " [251, 2067, '2022-01-22'],\n",
       " [79, 533, '2022-01-23'],\n",
       " [38, 212, '2022-01-24'],\n",
       " [49, 615, '2022-01-26'],\n",
       " [74, 1472, '2022-02-13'],\n",
       " [73, 2325, '2022-02-27'],\n",
       " [32, 176, '2022-03-04'],\n",
       " [209, 2015, '2022-03-23'],\n",
       " [32, 439, '2022-04-14']]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_x[\"https://crossword-solver.io/clue/intensify/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3efaf4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_timers = []\n",
    "several_timers = []\n",
    "no_spikes = []\n",
    "\n",
    "for x in list_overperforming:\n",
    "    if x[1] == 1:\n",
    "        one_timers.append(x[0])\n",
    "    elif x[1] == 0:\n",
    "        no_spikes.append(x[0])\n",
    "    else:\n",
    "        several_timers.append(x[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6bbc2e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_evergreen = []\n",
    "\n",
    "for keys,values in dict_x.items():\n",
    "    counter = 0\n",
    "    for y in range (len(values)):\n",
    "        if values[y][0] > 50:\n",
    "            counter = counter + 1\n",
    "    if counter > 30:\n",
    "        list_evergreen.append([keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4e4a8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "new_no_spikes = []\n",
    "for y in no_spikes:\n",
    "    total_clicks = 0\n",
    "    clicks = []\n",
    "    dates = []\n",
    "    for x in dict_x[y]:\n",
    "        total_clicks = total_clicks + x[0]\n",
    "        clicks.append(x[0])\n",
    "        dates.append(x[2])\n",
    "        \n",
    "    new_no_spikes.append([y,total_clicks,clicks,dates])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "37f34f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(new_several_timers, columns=[\"URL\", \"Clicks\", \"Impressions\", \"Date\"])\n",
    "df.to_csv('several_timers.csv', index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
